# 网络
参考书籍：《图解TCP/IP》，《TCP/IP详解 卷一》，《图解HTTP》，《HTTP权威指南》
## OSI网络模型以及各层协议
### 七层模型
  物理层
    负责位从一个节点到另一个节点的传输
  数据链路层
    数据格式为帧，传输之间地址为物理地址
  网络层
    数据格式为分组，传输之间地址为IP地址
  传输层
    数据格式为报文，传输之间地址为端口地址
  会话层
    负责对话控制和同步
  表示层
    负责翻译、加密和压缩数据
  应用层
    负责向用户提供服务器
### 广播
广播域是一个二层概念，所有能够接收到同一个广播的设备处于同一广播域。而所有的三层以下的设备（不包括第三层）都是不能隔离广播的，所以所有由交换机，网桥，集线器连接起来的设备都处于同一个广播域，不管他们的网段是否相同。
而Vlan也是一个二层概念，通过配置交换机接口来限制包的转发。所以Vlan相当于基于原来的广播域划分更小的广播域。也就是说，一个没有vlan的广播域添加了vlan之后，会被分成新的更小的广播域。而在没有vlan的时候，我们默认所有设备都属于vlan1，于是广播域内所有设备都属于vlan1。所以得出结论：广播域的范围等于vlan。
网段是一个第三层概念，用于路由寻址之类的。一般一个路由器接口对应着一个网段，如果两个接口接着同一个路由器，会出现冲突。所以我们认为一个路由器端口（逻辑上或者物理上）对应着一个网段。而广播被路由器阻拦，所以一个广播域是无法跨越路由器存在的，在这时候我们能认为网段与广播域的范围一样大。
但是如果没有路由器的存在，那么就没有了第三层的概念了，不过我们仍然可以为设备配置ip，划分网段。这时候所有的网段在没有路由器的存在下，都属于一个广播域，这时候广播域的范围大于等于网段。
总结：广播域的范围等于vlan（假设没有设置vlan的时候所有设备都属于vlan1）；在有路由器存在的情况下，网段和广播域是一样大的；在没有路由器的情况下，广播域大于等于网段。
### 集线器、交换机和路由器的区别
集线器和交换机区别
1. 集线器工作在物理层，交换机工作在数据链路层
2. 集线器传输速度没有交换机快
3. 集线器的数据传输方式是广播方式，而交换机的传输是有目的的，只在目的的MAC找不到的情况下会使用广播
交换机和路由器区别
1. 交换机工作在数据链路层、路由器工作在网络层
2. 交换机根据MAC地质寻址、路由器根据IP地址寻址
3. 转发速度不同：交换机转发速度快，路由器相对较慢
### 网桥、网卡、网关
网桥：一个局域网与另一个局域网之间建立连接的桥梁、工作在数据链路层上
网关：实质上是一个网络通向其他网络的IP地址、工作在应用层和传输层
网卡：
  将电脑的数据封装为帧，通过网线(或者在无线网络情况下是电磁波)将数据发送到网路上去。
  接收网络上其他设备传过来的帧，并将帧重新组合成数据，发送到所在的电脑中。
### 静态路由和动态路由
  静态是由管理员手工配置的，适合比较简单的网络或需要做路由特殊控制。
  而动态则是由动态路由协议自动维护的，不需要人工干预，适合比较复杂大型的网络
## TCP & UDP & IP ... 各个协议
### IP地址A、B、C类
### TCP与UDP之间的区别 
* TCP是面向连接，UDP是无连接的，
  面向连接就是TCP在传输前先发送连接请求和应答包，确定双方能够正常传输后，才传输。
  而UDP基于无连接，发送之前不考虑不能保证数据一定送到
*  TCP能保证可靠传输，UDP不能。
*  TCP结构较复杂，UDP结构简单，消耗资源少，建立过程较快。
*  TCP面向字节流的，UDP是面向报文的
*  TCP连接是点到点，UDP则可以n对n。所以广播和多播只能用UDP
*  TCP有确认、重传、拥塞控制机制。UDP在没有建立连接或者对方已经退出的情况中仍然会发送数据
*  TCP头部(20字节)比UDP头部(8字节)大

**为什么TCP是可靠的？如何保证可靠性**                 
   对于可靠性，TCP通过以下方式进行保证:
   * 数据包校验
    如果校验出包有错，就会丢弃报文段并且不给响应。这样发送端数据超时后会重发数据。
   * 对失序数据包重排序
    TCP会对失序数据进行重新排序，然后才交给应用层。
   * 丢弃重复数据
    TCP能够丢弃重复数据
   * 应答机制
    当TCP收到包的时候会回发一个确认段，确认自己收到了
   * 超时重发
    当TCP发出一个段时候，会启动一个定时器，等待目的端确认收到，如果超时就会重发报文段
   * 流量控制
    TCP连接的每一方都有固定大小的缓冲空间，TCP的接收端只允许接收接收端缓冲区所能够接纳的数据。

### TTL概念
### TCP和UDP分别对应协议(应用层)
TCP: STMP, TELNET, HTTP, FTP
UDP: DNS,TFTP,RIP,DHCP,SNMP
### TCP和UDP应用场景    
TCP:对效率要求低，对准确性要求较高 (如文件传输、重要状态的更新等)
UDP:对效率要求高，对准确性要求较低 (如视频传输、实时通信等)。
TCP: SMTP、TELNET、HTTP、FTP
UDP: RIP、DNS、BOOTP、DHCP、SNMP、NFS
### IP首部，TCP首部，UDP首部 
IP首部 20字节
TCP首部 20字节，如果有选项可以到60字节
UDP首部 8字节
### 列举你所知道的tcp选项，并说明其作用。
tcp选项部分是TCP为了适应复杂的网络环境和更好的服务应用层而进行设计的。
选项部分最长可达40字节。
MSS选项：
	4byte。MSS是一个TCP报文段中数据字段的最大长段(不包括TCP的头部)。TCP在握手中，每一方都会通告期望收到的MSS(MSS只出现在SYN数据包中)。如果一方不接受另一方的MSS则定位默认值536bytes
	MSS的合理值应为保证数据包不分片的最大值
窗口扩大选项：
	用途就是名字。
	扩大窗口
选择确认选项SACK Selective Acknowledgements：
	收到的报文无差错，但是未按序列号且中间缺失一些序列号只需要重传已经正确到达的数据。就需要选择重传技术。
	指明一个边界要用到4字节。使用边界最多能传到4个字节块的边界信息。且还需要2个功能字节，一个字节用来指明使用SACK选项，另一个字节指明选项需要的字节。
时间戳选项：
	占10个字节。
	用来计算往返时间和防止回绕
	防止回绕：序列号只有32位，每用完以后就会重新使用。假设有高速网络，避免以前发送的序列号被重复。
NOP:
	没什么用，主要用了填充垫片。TCP的头部必须是4Byte的倍数，但是大多数的TCP选项不是4Byte的倍数，此时就是用1个或多个填充
### 如何实现可靠的UDP
  在UDP上实现一个TCP协议是没有意义的
  一般就实现个确认 + 重传，为每一个发送的包分配一个包id，当一端接收到包后需要发送回ack确认包id
  然后时间到了没有ack就重发
## keepalive 是什么东东？如何使用？
http和tcp都有keep-alive。tcp长连接在发包完毕后会等待一段时间再断开连接。
Http的keep-alive是为了让TCP活得更久一点，以便使用同一个传送多个数据。
实现原理：
	httpd守护进程在传送完最后一个响应后，会等待keepalive_timeout秒，如果一直没有收到浏览器的http请求，然后才关闭这个连接。
tcp的keep-alive是为了检查TCP的连接状态
它的实现原理：
	过一段时间后自动发送一个数据为空的报文，如果有响应，说明对面还在线



### TCP三次握手与四次挥手,详细说明TCP状态迁移过程 
三次握手
1. 客户端发送SYN=1，SEQ=X的帧发送给Server，客户端进入SYN_SENT状态等待服务器确认
2. 服务器收到SYN帧，发送一个SYN=1,ACK=1,ack=J+1,SEQ=K的帧给客户端确认连接请求，服务器进入SYN_RCVD状态
3. 客户端收到SYN+ACK后，发回K=1,ack=K+1，此时服务器检查该帧，确认则连接建立成功，服务器和客户端进入Established状态可以开始传输数据。

四次挥手
1. 客户端发送FIN到服务器，关闭客户端到服务器的数据传送，客户端进入FIN_WAIT1状态。
2. 服务器收到FIN，发回一个ACK，服务器进入CLOSE_WAIT状态。此时客户端仍可接收来自服务器的数据
3. 客户端接收到ACK帧后进入FIN_WAIT2状态
4. 服务器发送FIN，关闭服务器到客户端的数据传送。服务器进入LAST_ACK状态。
5. 客户端收到FIN帧后，发回一个ACK帧，客户端进入TIME_WAIT状态等待2MSL后进入CLOSED状态，服务器进入CLOSED状态

扩展:
**2MSL是什么状态？为什么TIME_WAIT状态需要等2MSL后进入CLOSED状态?**
2MSL是最大文段生存时间
假如网络不太好服务器没收到最后的ACK帧则会重发FIN帧，所以要先等待，用于重发可能丢失的ACK报文。

** time_wait状态是什么,为什么会有time_wait状态？哪一方会有time_wait状态，如何避免time_wait状态占用资源（必须回答的详细）**
TCP连接中主动关闭连接的一方会有time_wait状态
在/etc/sysctl.conf
修改net.ipv4.tcp_tw_recycle（开启重用，允许将time_wait sockets重新用于新的TCP连接）
/tcp_fin_timeout（开启TCP连接中TIME_WAIT socket的快速回收）
/tcp_keepalive_ * （用于检测连接存活的次数）这几个参数

**三次握手为什么不是两次或者四次？为什么是四次挥手**
三次握手：
四次的次数太多没有必要。
不是两次是为了防止已失效的链接请求报文突然又传送到了服务端，因而产生错误。
如果采用两次的话，当服务器发出确认帧的时候链接就建立了。
假设A发出的连接请求段（SYN+ACK）不是丢失而是长时间滞留，延迟后才到达B，这时B如果收到，就会同意建立连接，等待A发送资源，这样就会浪费资源。
四次挥手：
因为TCP是全双工的，一端停止发送数据后仍可以接收数据。有时候可能服务器需要时间处理数据不能立即发送响应数据回来。
**TCP三次握手的缺陷**
  客户端不断进行请求连接的时候，服务器端会为每一个请求创建一个连接，并向其发送确认报文，然后等待客户端进行确认。
  DDos攻击：
    利用大量的合理的服务请求占用过多的服务资源，使合法用户没法得到服务的响应。
    SYN-Flood或叫SYN泛洪攻击就是攻击的一种。
  SYN-Flood攻击: 
    通过向网络服务所在端口发送大量的伪造源地址的攻击报文，就可能造成目标服务器中的半开连接队列被占满，从而阻止其他合法用户进行访问。
  防范:
    无效连接监视释放 
      这种方法不停的监视系统中半开连接和不活动连接，当达到一定阈值时拆除这些连接，释放系统资源。这种绝对公平的方法往往也会将正常的连接的请求也会被释放掉，”伤敌一千，自损八百“
    使用SYN 2Proxy防火墙


### TCP重发机制，Nagle算法
	Nagle算法：
		在一个tcp连接上只能有一个没有被确认的数据包，在这个确认没有收到之前不发送任何数据报相反收集小的报文段以便到时候一起发送。
		但是以下情况例外：
			1.包长度达到MSS
			2.如果该包含有FIN
			3.设置了TCP_NODELAY选项
### TCP的拥塞控制使用的算法和具体过程
TCP处理拥塞的一般策略基于三个阶段：慢速启动、拥塞避免、拥塞检测
* 慢速启动
   从小到大逐渐调整拥塞窗口大小。用很慢的传输速率启动，但迅速的增加到阈值。
   指数增长：
    开始的时候设置窗口大小为1MSS，每次接收到窗口中的一个段的确认之后，窗口大小就增加一个MSS值。
    按指数规律增加直到阈值
* 拥塞避免
   为了避免拥塞，而减少增加的速率
   加性增加：
    当拥塞窗口达到阈值后，指数增加停止，开始加性增加，每次整个窗口所有段的确认之后，窗口大小才增加1MSS。
    如此增加直到检测到拥塞
* 拥塞检测：
    发送方推测发生拥塞的唯一方法时从重传的要求，但是重传的情况有两种:快重传或者重传计时器到时
    **快重传**
      快重传要求接收方在收到一个失序的报文段后就立即发出重复确认而不要等到自己发送数据报的时候捎带确认。发送方只要一连收到三个重复确认就应当立即重传对方尚未收到的报文段，而不必等待等待设置重传计时器时间到期
    在快重传(接收到三个ACK)的情况下，TCP会设置阈值为当前拥塞窗口的一半，将cwnd设置为阈值，开始拥塞避免状态
    在计时器到时的情况下，会设置阈值为当前拥塞窗口大小的一般，设置cwnd为1MSS，启动慢速启动状态

###TCP的流量控制
TCP采用滑动窗口实现流量控制。
窗口大小 = min(cwnd,rwnd)，rwnd是拥塞窗口、cwnd是接收窗口，接受窗口值是在另一端的确认段中宣布的值。拥塞窗口的值由拥塞控制机制确定
###ARP的机制，RARP的实现
ARP工作原理:
每个主机都会在ARP缓冲区建立一个ARP列表，表示IP和MAC的映射关系
当主机要发送数据时，首先检查ARP列表中是否有对应IP地址的目的主机的地址，
如果有则直接发送，如果没有，向本网段的所有主机发送ARP包，包含源地址IP地址、源主机MAC地址、目的主机IP地址
所有主机接收到后检查自己的IP地址是不是目的地址，如果是返回自己的MAC地址。
源主机接收到响应，将目的主机的IP和MAC地址写入ARP列表，并向目的主机发送消息。
### Ping和TraceRoute实现原理
 说一下ping这个命令底层是做了什么吧，ping本机和ping远端过程上有哪些区别
	Ping命令利用ICMP协议进行工作。
	A向B发送echo request控制消息，B正确接收后即发回echo reply控制消息。
TraceRoute
	Ping虽然可以侦测路由，但是ping收到ip头的限制，不能完全记录所经过的路由器
	TraceRoute收到目的主机IP后，会给目的主机发送一个TTL=1的udp数据包，在经过的第一个路由器收到这个数据包之后，自动把TTL减去1，而TTL变成0之后，路由器就把这个数据包抛弃了，并且同时给主机发送主机不可达的ICMP数据包，主机收到数据包后，再发送TTL=2的数据报，这样就会得到第二个路由的地址，如此往复。
	如何判断UDP到没到达目的主机？Traceroute发送的是端口>3----的udp报，所以到达目的主机的时候，目的主机只能发送一个端口不可达ICMP数据包回主机，这样主机就知道目的主机到了。
### ICMP协议
ICMP是因特网控制消息协议(Internet Control Message Protocol)
用于补充IP协议所缺失的差错控制和管理查询的机制
### DNS解析地址过程
电脑发出DNS请求到本地DNS服务器
本地DNS服务器查询缓存记录，有则直接返回结果，没有则向DNS根服务器进行查询。
告诉本地DNS服务器域服务器地址
本地服务器向域服务器发出请求
域服务器告诉本地DNS服务器域名的解析服务器的地址。
本地向解析服务器发出请求，收到域名和IP的对应关系，发出IP给用户电脑，并保存对应关系以备下次查询。

### 地址栏输入一个url到最后内容出现在页面上，中间经历了哪些过程
    1. 浏览器查询DNS，获取域名对应的IP地址。
    具体过程包括
      查询浏览器缓存，
      读取本地的Host文件
      路由缓存
      并对DNS服务器(本地域名、顶级域名、根域名)进行查询等。
    如果本地查不到，可以从名字服务器中请求递归应答。也可以请求迭代应答等从其他服务器查询。
    2. 浏览器获得IP地址以后，向对应的服务器发起三次握手，请求连接。
    3. 服务器接收到请求，并根据路径映射到特点的请求处理器进行处理，并将处理结果和响应的视图返回给浏览器
    4. 浏览器解析并渲染视图，如果遇到对JS、CSS、图片等静态资源的引用，则重复上述步骤向服务器请求这些资源
    5. 浏览器根据请求到的资源、数据渲染页面最终对用户显示一个完整的页面

## http相关
### http端口号：80
	其实我们输入网站的时候浏览器就帮你自己加上去了
### 长连接、短连接
  短连接：
    每进行一次HTTP操作，就建立一次连接，但任务结束就中断连接
  长连接：
    网页打开完成后，客户端和服务器之间的TCP连接不会关闭，后续客户端再次访问的时候会继续使用这个连接。
    可以通过设置keep-alive属性设置保持的时间
### Session、Cookie、Application概念、对比
Cookie用于记录用户状态，是计算机存储在浏览器目录的文本文件。
Session是会话，指从一个浏览器窗口打开到关闭这个期间。如果说Cookie是在客户端保持状态的话，Session就是在服务器端保持状态的方案。
不过Session常常需要借助于Cookie或URL重写机制来达到保存标识的目的
两者对比:
* Cookie存在安全隐患，而Session存在服务器端，相对更加安全
* Cookie有大小限制，而Session相对来说没有，理论上只与服务器的内存大小有关。
* Session是保存在服务器上存在一段时间才会消失，如果session过多会增加服务器的压力。

### http/https 1.0、1.1、2.0的特点和区别
  https://www.jianshu.com/p/52d86558ca57
  1.0 规定浏览器只与服务器保持短暂的连接，每次请求都需要与服务器建立一个tcp连接，完成后就断开
         由于连一次就断，所以效率很低，每次请求都经历慢启动和三次握手
  1.1 支持持久连接，在一个TCP连接中可以传输多个HTTP请求和响应。性能优化PC端很明显，但是移动端一般。因为请求分散
  2.0 完全的多路复用，只需要一个连接可实现并行。
      采用二进制格式而非文本格式，二进制分帧: 在应用层和传输层中添加一个二进制分帧层，改进传输性能
### get/post 区别
    1. 功能上讲：get重点从服务器上获取资源，post重点是更新服务器上的数据
    2. 从请求参数形式上看：get传输数据是通过url请求，以field = value的方式，放在?后，post传输参数则是放在request体中进行传输
    3. 从安全性上看：get是不安全的，因为url是可见的，容易泄漏
    4. 从请求大小看：get传输数量小受url长度限制但效率较高，post可以传输大量数据
    5. 从REST服务角度上看，GET是幂等的，即读取同一个资源总是得到相同的响应，而POST不是幂等的

###怎么理解HTTP的？
  https://www.zhihu.com/question/53226983
###http的启动方法，没答出来
###HTTP返回状态码
  1xx指示信息-表示请求已接收、继续处理
  2xx成功-表示请求已被成功接收、理解、接收
    200 正常处理
    204 受理了请求但是没有资源
    206 客户端只请求了一部分，服务器只对部分资源执行资源方法
  3xx重定向
    301 永久性重定向
    302 临时重定向
    303 与302类似，但是希望客户端通过GET方法重定向
    304 发送附带条件的请求时，条件不满足时返回
    307 临时重定向，与302类似，但是强制要求POST方法
  4xx客户端错误—请求有语法错误或者请求无法实现
    400 请求语法有错误，服务器无法识别
    401 请求需要认证
    403 Forbidden 资源不可用，权限不够无法访问
    404 无法找到指定位置的资源 
  5xx服务端错误
    500 服务器内部错误
    503 服务器正忙
###http 协议头相关
http数据由请求行，首部字段，空行，报文主体四个部分组成 
首部字段分为：通用首部字段，请求首部字段，响应首部字段，实体首部字段

###https与http的区别？如何实现加密传输？加解密方式？
  HTTPS需要用到CA申请证书
  https在传输数据前需要客户端和服务器之间先握手，确认双方加密传输数据的密码信息。
  HTTP的连接是简单的，无状态的，而HTTPS是HTTP+SSL构建的可以进行加密传输、身份认证的网络协议，比HTTP协议安全
  使用的TLS/SSL协议
  **TLS/SSL**
  非对称加密 + 对称加密 + 散列算法



#数据库
主要参考书籍：《数据库系统概念》，《高性能MySQL》
##SQL语言(内外连接，子查询，分组，聚集，嵌套，逻辑)
##MySQL索引方法？索引的优化？
##InnoDB与MyISAM区别？
##事务的ACID
##事务的四个隔离级别
##查询优化(从索引上优化，从SQL语言上优化)
##B-与B+树区别？
##MySQL的联合索引(又称多列索引)是什么？生效的条件？
##分库分表

# 操作系统
主要参考书籍：《现代操作系统》，《APUE》，《UNP》，《LINUX内核设计与实现》，《深入理解LINUX内核》
### 文件系统管理的最小磁盘空间单位
是簇
## 进程通信的目的
数据传输、共享数据、通知、资源共享、进程控制
### 进程间通信方式
管道、消息队列、信号量、共享内存、SOCKET、信号
管道（包括无名管道和命名管道）、消息队列、信号量、共享存储、Socket、Streams
管道是半双工的，速度慢。匿名管道只能在有亲缘关系的进程间使用。
消息队列：存放在内核中，容量受系统限制。一个消息队列有一个标识符。是面向记录的。消息队列可以实现信息的随机查询。
信号量用于进程间互斥与同步
信号
	信号其实通常是一个数，可以被发送到一个或一组进程。
	信号的目的：1.让进程知道特定的时间发生 2.使进程执行自己代码中的信号处理程序。
共享内存：
最快的一种IPC，因为进程直接对内存操作，因为多个进程可以同时操作，所以需要同步，通常和信号量结合一起使用。
socket
	可用于不同机器间的进程通信
**匿名管道与命名管道的区别**
  匿名管道只能在具有公共祖先的两个进程间使用。
**共享文件映射mmap **
  mmap建立进程空间到文件的映射，在建立的时候并不直接将文件拷贝到物理内存，同样采用缺页终端。mmap映射一个具体的文件可以实现任意进程间共享内存，映射一个匿名文件，可以实现父子进程间共享内存。
 
## 共享内存的使用实现原理（必考必问）
	共享内存就是允许两个不相关的进程访问同一个逻辑内存。
	共享内存并未提供同步机制，也就是说进程对共享内存操作时，并没有机制阻止另一个进程读取。所以一般使用如信号量等同步机制同步
	共享内存的底层是如何实现的
		就是将不同进程的虚拟内存地址映射到同一块物理内存地址上
	共享内存的生命周期随内核而非线程
**共享内存段被映射进进程空间之后，存在于进程空间的什么位置？**
	紧靠在栈之下堆之上
**然后共享内存段最大限制是多少？**	
	最大限制为32M
	    11. mmap映射底层源码

    12. do_mmap在内核中有哪几种使用方式（匿名、文件映射、共享）
## 信号：列出常见的信号，信号怎么处理？
**常见信号**
2   SIGINT   terminate   来自键盘的中断ctrl+c
9   SIGKILL  terminate   强迫进程终止kill -9
15 SIGTERM terminate 进程终止(不带参数时kill默认发送的信号)
19 SIGSTOP stop		停止进程执行
18 SIGCONT continue	 如果进程已停止则恢复执行
11 SIGSEGV dump	       无效的内存引用	
14 SIGALRM terminate 实时定时器时钟
20 SIGTSTP  stop	 从tty发出停止进程ctrl+z
**信号怎么处理？**
1. 忽略信号
2. 执行与信号相关的默认操作terminate:终止、dump终止进程如果可能会创建包含进程执行内容的核心转储core dump文件、ignore：忽略信号、stop：进程被停止，把进程置为TASK_STOPPED状态、continue: 如果进程被停止，就把它置为TASK_RUNNING状态
3. 执行相应的信号处理函数捕获信号。

### 进程与线程区别?线程比进程具有哪些优势？ 
  进程是程序的一个执行、是**资源调度的基本单位**，拥有独立的地址空间，而同一进程中的线程共享该进程的地址空间。
  线程是进程的实体，是**CPU调度和分派的基本单位**。它是比进程更小的能独立运行的基本单位。
  线程的优势在于线程间通信比较方便，因为共享数据。
## 多线程之间共享和私有资源
共享：地址空间、全局变量、子进程、闹铃
不共享：程序计数器、寄存器、栈、状态字
###进程同步的方式
  信号量、消息传递(send、receive)
  管程：是由一个或多个过程、一个初始化序列和局部数据组成的软件模块，其主要特点如下：
    任何时候管程中只能有一个进程在管程中执行，调用管程的任何其他进程都被阻塞，以等待管程可用。
## 查看一个进程打开的文件怎么查看
	lsof -c xxx 查看xxx程序所打开的文件信息
	lsof /filepath/file 查看文件正在被谁使用
	lsof -i:端口号 查看端口号所使用的进程号
## 如何查看指定进程打开的端口号
	ps -ef | grep pid
	netstat -anp | grep pid

### 线程同步的方式
  事件：允许线程在处理完一个任务后，主动唤醒另外一个线程执行任务
  临界区：当多个线程访问独占的共享资源时，使用临界区对象
  互斥量：互斥对象和临界区对象非常相似，只是还允许在进程间使用，相比临界区更消耗资源。
  信号量
### 什么时候用多进程？什么时候用多线程？
从cpu调度，上下文切换，数据共享，多核cup利用率，资源占用，等等各方面回答
  多进程，一个进程崩溃不会影响其他的进程，但是进程的切换和通信比较麻烦
  多线程，数据共享和通信比较方便，但是一个线程死亡的话，其他线程也崩溃了
  所以如果需要频繁交互的，频繁对同一个对象进行不同的处理，选择多线程合适
### 什么是缓冲区溢出?有什么危害，其原因是什么?
	缓冲区溢出是指计算向缓冲区填充的数据超出了缓冲区本身的容量，溢出的数据覆盖了合法数据。
	危害有：程序崩溃、跳转执行恶意代码
	主要原因是程序中没有仔细检查用户输入。
## LINUX中进程和线程使用的几个函数？ 
## 如何实现守护进程？
守护进程daemon，是运行在后台的特殊进程。这些进程没有控制终端不能直接和用户交互。
**实现守护进程**
* 调用umask(0)将文件模式创建屏蔽字设置为0
* fork一次以后父进程exit
* setsid创建新会话
	成为守护进程的基本条件是不和任何终端有瓜葛。
	在一个会话里面，可以包含多个进程组，也就是说进程有可能和其他进程共享了一个会话终端
* 第二次fork，禁止进程重新打开控制终端
* 调用chdir将根目录作为子进程的工作目录
* 子进程关闭从父进程继承的所有不需要的文件描述符
* 重定向标准输入、输出、错误
## linux的内存管理机制是什么？
进程内存组成：同上面的C分区，代码段、数据段、bss区、栈、堆
**虚拟内存的作用？实现？**
Java对进程内存采用虚拟内存，每个进程都有自己互不干涉的进程地址空间。可以保护操作系统，并使用比实际内存更大的区域。
进程地址空间通常被划分为用户空间和内核空间，只有用户进程进行系统调用的时候才能访问系统空间。
进程分配内存时，从内核获得的是虚拟的地址，并且此时并没有获得物理内存，直到真正的去访问的时候，才会去页请求，分配实际页面，此时内核才真正为进程分配物理页，建立对应的页表。
## 内存池的作用？STL里内存池如何实现？
## 进程空间和内核空间对内存的管理不同？
## Linux的slab层
	页表管理内存虽然方便，但是容易产生碎片。
	slab会将小块内存看做对象，用完后不直接释放而是放到缓存池里。
	slab不但避免了内存内部分片带来的不便。并且可以通过硬件缓存提高访问速度。
	slab并非脱离伙伴关系而独立存在的机制，实际上，slab将页面撕碎成多个内存小块以供分配使用kmalloc和kfree分配和销毁内存
### 伙伴算法
	Buddy System把所有的空闲页框分为11块链表，每块链表中包含特点的连续页框地址空间。如第n块包含2^n个连续的页框
	优点是解决了外部碎片问题和大内存分配
	缺点是容易造成内部碎片和浪费问题
## 高端内存
	linux中内核使用3G-4G的线性地址空间，也就是说总共只有1G的地址空间可以用来映射物理地址空间。但是，如果内存大于1G的情况下呢？是不是超过1G的内存就无法使用了呢？为此内核引入了一个高端内存的概念，把1G的线性地址空间划分为两部分：小于896M物理地址空间的称之为低端内存，这部分内存的物理地址和3G开始的线性地址是一一对应映射的,也就是说内核使用的线性地址空间3G--(3G+896M)和物理地址空间0-896M一一对应；剩下的128M的线性空间用来映射剩下的大于896M的物理地址空间，这也就是我们通常说的高端内存区。
	所谓的建立高端内存的映射就是能用一个线性地址来访问高端内存的页。如何理解这句话呢？在开启分页后，我们要访问一个物理内存地址，需要经过MMU的转换，也就是一个32位地址vaddr的高10位用来查找该vaddr所在页目录项，用12-21位来查找页表项，再用0-11位偏移和页的起始物理地址相加得到paddr,再把该paddr放到前端总线上，那么我们就可以访问该vaddr对应的物理内存了。在低端内存中，每一个物理内存页在系统初始化的时候都已经存在这样一个映射了。而高端内存还不存在这样一个映射(页目录项，页表都是空的)，所以我们必须要在系统初始化完后，提供一系列的函数来实现这个功能，这就是所谓的高端内存的映射。那么我们为什么不再系统初始化的时候把所有的内存映射都建立好呢？主要原因是，内核线性地址空间不足以容纳所有的物理地址空间（1G的内核线性地址空间和最多可达4G的物理地址空间），所以才需要预留一部分（128M）的线性地址空间来动态的映射所有的物理地址空间，于是就产生了所谓的高端内存映射。
## Linux的进程调度策略
	多级反馈队列调度算法
## Linux进程分为两种
	实时进程和非实时进程
	实时进程的优先级（0~99)都比普通进程的优先级(100~139)高，且直到死亡之前一直是活动进程。当系统中有实时进程运行时，普通进程几乎是无法分到时间片的
## 优先级
	优先级有动态优先级，静态优先级，实时优先级
	静态优先级不随时间改变，内核不会主动修改，只能通过系统调用去修改它。
	动态优先级调度程序通过或减少进程静态优先级来奖励IO消耗型进程或惩罚CPU消耗型进程，这样调整后的优先级变为动态优先级
	实时优先级只对实时进程有效，与动态优先级成线性关系，而不随时程运行而改变。
	动态优先级范围 0-139
	静态优先级 static_prio = max_rt_prio(100) + nice + 20 	
### 进程调度策略
FCFS先来先服务
SJF短作业优先
FPF最高优先权优先：又分为非抢占式和抢占式，区别是进程一旦运行后遇到另一个优先级更高的线程调度程序会不会停止当前进程
高响应比算法：
	RP = (等待时间+运行时间)/运行时间
时间片轮转法：
	早起的时间片轮转算法：系统将所有的进程按FCFS原则排成一个就绪队列，每次调度的时候把CPU分配给队首进程，并令其执行时间片。时间片的大小从几ms到几百ms，执行完毕后，停止进程执行并送往就绪队列的末尾然后调度队首继续上述步骤。这样保证就绪队列中的所有进程在一给定的时间内均能获得一时间片的处理机执行时间。
多级反馈队列调度算法：
	设置多个就绪队列，并为各个队列赋予不同的优先级，从1-n队列优先级逐个降低，该算法赋予各个进程中执行时间片的大小也各不相同，优先级越高的队列中，时间片就越小。
	每当一个新进程进入内存后，就把它放入第一队列的末尾，按照FCFS原则排队等待调度，一个时间片执行完毕后如果未完成就放入第二队列的末尾，同样按照FCFS原则调度。如此下去直到n个队列。
	仅当第一队列空闲的时候调度程序才调度第二队列中的进程运行，仅当第1~(i-1)的队列均空时，才会调度第i队列中的进程运行，如果处理机正在第i队列中为某进程服务时，又有新进程进入优先权较高的队列，则此时新进程将抢占正在运行进程的处理机。
## 交互进程通过平均睡眠时间而被奖励；
### 死锁，产生的条件，死锁的避免；
  死锁:在两个或者多个并发进程中，如果每个进程持有某种资源而又等待其它进程释放它或它们现在保持着的资源，在未改变这种状态之前都不能向前推进，称这一组进程产生了死锁。通俗的讲就是两个或多个进程无限期的阻塞、相互等待的一种状态。
  产生的条件:
  资源互斥使用：进程对其申请的资源进行排他控制，其他进程申请该资源只能等待。
  非剥夺控制：占有资源的进程只能自己释放资源，其他进程不能抢
  零散请求与控制：进程可以按需求逐次请求，而不是一次要求全部资源才能执行。
  循环等待：等待资源的进程形成一个链，链上的进程都在等待下一个进程占有的资源，造成了死循环。
# Linux命令行
## Linux命令 在一个文件中，倒序打印第二行前100个大写字母
  cat filename | head -n 2 | tail -n 1 | grep '[[:upper:]]' -o | tr -d '\n'| cut -c 1-100 | rev 
## 与CPU，内存，磁盘相关的命令(top，free, df, fdisk)
  top:查看各进程资源占用情况          
  free：内存使用情况
  df:大 
## 网络相关的命令netstat，tcpdump等
**netstat**
	-a 显示所有选项
	-t 仅显示tcp相关选项
	-u 仅显示udp相关选项
	-n 拒绝显示别名，显示数字的全显示为数字
	-l 仅列出Listen的服务状态
	-r 显示路由信息，路由表
	-p 显示相关的进程名
	-c 每隔一个固定时间，执行该命令
	常用
		netstat -p
		显示进程名，常用于kill占用端口的程序
		netstat -an | grep ':portnum'
		找出指定端口的值

**tcpdump**
	监视网络接口(一般是eth0)上的所有数据包
	常用
		tcpdump host xxx/ipaddress 打印所有进入或离开xxx的数据包
		tcpdump host xxx and \(xxx or xxx\) 打印之间通信的数据包
        tcpdump ip ... 打印ip数据包
        tcpdump -i eth0 src host hostname 截获hostname发送的所有数据包
  		tcpdump -i eth0 dst host hostname 截获hostname发送的所有数据包
  		tcpdump port portnum 指定端口portnum
  		tcpdump  -XvvennSs 0 -i eth0 tcp[20:2]=0x4745 or tcp[20:2]=0x4854
        抓取HTTP包
** ipcrm, ipcs **
	ipcrm命令删除一个或多个的消息队列、信号量集或共享内存标识
		-M shmkey 移除用shmkey创建的共享内存段
		-m shmid  移除用shmid创建的共享内存段
		-Q msqkey 移除用msqkey创建的共享内存段
		-q msqid 移除用msqid创建的共享内存段
		-S semkey 移除用semkey创建的共享内存段
		-s semid  移除用semid创建的共享内存段
	ipcs命令往标准输出写入一些关于活动进程间通信工具的信息。如果没有标志，ipcs命令用简短格式写入一些关于当前活动消息队列，共享内存段，信号量，远程队列，本地队列标题
		-a 默认 打印所有当前系统进程间通信方式的信息
		-m 打印出所有使用共享内存进行进程间通信的消息
		-q 打印出所有使用消息队列进行进程间通信的消息
		-s 打印出所有使用信号进行进程间通信的消息
** sed, awk, grep **
  三个超强大的命名，分别用与格式化修改，统计，和正则查找
  sed十个编辑器、grep以行查找、awk更强增加分隔符
  grep更适合单纯查找后匹配、sed适合编辑、awk适合格式化文本，对文本进程复杂的处理
  grep [-acinv] [—color=auto] ‘re’ filename
    -a将
    -c计算匹配的次数
    忽略大小写
输出行号
反向选择即显示出不匹配的一行
—color=auto 关键字部分
 awk [-F fs] [-v var=value] [‘{prog}’ | -f progfile] [file …]
 fs分隔符,是一个字符串或者正则表达式，指定的是分割各项的字符。可使用多个分隔符 ‘[ ,]'表示先使用空格分隔。然后对分隔结果使用,分割
 赋值一个用户定义变量
内置变量 
NR 行号
NF 当前行的字段个数
从脚本文件中读取awk命令
prog中$1、$n表示第n项,$0表示完整的输入记录
var设置后可以使用在prog中
sed [-hnV] [-e command] [-f<script文件>] [文本文件]
以行为单位的处理数据
mac的sed有点问题 需要\后换行输入
-h或—help显示帮助
-n或—quiet或—silent仅显示只有被script处理后会被输出到结果中
-v 显示版本信息
-i 真的改变文件中的内容，别的都是改变显示
command的形式
[address[,address]] function[arguments]
其中address可以是$代表最后一行，或是一个数字代表行数,后面[1addr]表示单个地址，[2addr]表示[1addr,1addr]
Function有
[1addr]a 新增字串 
[2addr]c 取代n1,n2之间的行 为后跟的子串
[2addr]d 删除n1,n2之间的行
[1addr]i 从目前的一行插入后跟的文本
[2addr]p 将数据输出
[2addr]s/regularexpression/replacement/flags
  取代工作
ipcs和ipcrm命令
IPC命令，IPC即为进程间通信
ipcs可以查看共享内存、信号量、消息队列的状态
-a 显示所有的IPC设施
-q/-s显示所有的信号量、共享内存
ipcrm 手动清除指定的共享内存、消息队列、信号量
-M shmkey / -m shmid / -S semkey / -s semid / -Q msgkey / -msgid
清除用xxkey/id创建/标识的共享内存/消息队列/信号量
nl命令
列出文件内容并标注行号
##查找当前目录以及字母下以.c结尾的文件，且文件中包含”hello world”的文件的路径
##创建定时任务
  crontab -e 编辑定时任务 crontab -l 查看定时任务
  格式为分时日月周命令
  当分为*时表示每分钟执行一次，时为*时表示每小时执行一次
## IO模型
五种IO模型：阻塞IO，非阻塞IO，IO复用，信号驱动式IO，异步IO
  阻塞IO： 数据够了才返回，此阶段进程一直阻塞
  非阻塞：读了就返回，不管有没有获取到数据就返回。
  IO复用：调用select或poll这样的，可以告知系统有数据准备好了，系统再去读取
  信号驱动IO：数据准备好时信号告知开始IO
  异步IO：通过aio_read，内核等数据准备好后，复制到用户空间中执行事先准备好的函数。此过程中，用户进程从未阻塞
## 什么是粘包现象，如何避免粘包现象
	粘包现象：
## select，poll，epoll的区别
  select需要传fd_set，每次调用select都要遍历fd_set，开销比较大。并发数受fd_set的限制
  poll使用的是pollfd，不受fd_set的限制，其他一样
  epoll改进了前两个函数，epoll提供了三个函数，epoll_create（创建第一个epoll句柄）和epoll_ctl（注册要监听的事件类型）和epoll_wait（等待事件的发生），注册新的事件到epoll句柄中，会把所有的fd拷贝进内核，保证每个fd在整个过程中只会拷贝一次；epoll_ctl时把current挂一遍并未每个fd指定一个回调函数，当设备就绪，唤醒等待者时就会调用这个回调函数，这个回调函数就会把就绪的fd加入一个就绪链表。epoll_wait的实际工作就是查看有没有就绪的fd
**简单的epoll为什么比poll和select高效？**
1. 减少了用户态和内核态之间文件描述符的拷贝。
	select创建了3个fd_set并拷贝到内核中。内核检测到有就绪事件后，就修改用户传进来的fd_set以告知用户有就绪的文件描述符。将文件描述符fd_set拷贝传出到用户态并返回就绪的文件描述符的总个数。由于内核修改了传进来的fd_set，下次select时就必须要重新分配。
	poll系统调用将struct pollfd结构体数组拷贝到内核中进行监听，内核分配相关数据结构poll_list,用来存储监听的文件描述符，然后调用所有fd对应的poll(将current挂到各个fd对应的设备等待队列上)，内核在检测到有就绪事件后，就修改fd对应的revents的值用来告知用户有就绪的文件描述符，而events成员保持不变，因此下次调用poll时，应用程序无需重置pollfd类型的事件集参数。将之前传入的struct pollfd结构体数组拷贝传出到用户态，并返回就绪文件描述符的总个数。内核删除和文件描述符相关的数据结构，下次调用poll需要将struct pollfd重新传给内核，内核在重新拷贝一份，重新分配数据结构。
	epoll_create()函数会在内核创建一颗红黑树rb_node以及就绪链表rdllist(存放已经就绪的文件描述符)，接着用户执行的epoll_ctl()函数将epoll_event结构体拷贝传入内核，内核会在红黑树上添加相应的结点，内核将就绪的文件描述符事件复制到传入的poll_event结构体数组中返回给用户空间，系统调用在返回时采用mmap共享存储区，需要拷贝的次数大大减少。由于epoll创建的有关文件描述符的数据结构本身就存在于内核态中。下一次调用epoll系统调用时，不需要再次拷贝用户空间所要监听的文件描述符，也不需要重新构建红黑树和就绪链表等相关数据结构，直接沿用已经存在的数据结构。
2. 减少了对就绪文件描述符的遍历
	select和poll都是轮询遍历看看有没有就绪的。
	而epoll是回调的
3. select和poll只支持LT模式，而epoll支持ET模式
	LT电平触发：LT模式是默认的工作模式，当检测文件描述符上有事件发生并将此事件通知给应用程序，应用程序可以不立即处理该事件。下次调用会再次响应应用程序并通知此事件。
	ET边沿触发：当检测到文件描述符上有事件并将其通知给应用程序。应用程序必须立即处理该事件，如果没处理或者没处理完，下次调用不会再响应应用程序并通知此事件。只支持非阻塞socket
	PS:即使使用ET模式，一个socket上的某个事件还是可能被触发多次，这在并发程序中就会引发一个问题。比如一个线程在读取完某个socket上的数据开始处理这些数据的时候，而在数据的处理过程中这个socket上又有新数据可读，这时另一个线程被唤醒来处理新数据，于是就出现了两个线程同时操作一个socket的局面。因此需要使用epoll的EPOLLONESHOT事件实现。对于注册了EPOLLONESHOT事件的文件描述符，操作系统最多触发其上的一个读、写或异常事件，且只触发一次。当一个线程在处理socket时，其它线程是不可能有机会操作该socket的。注册EPOLLONESHOT事件的socket一旦被某个线程处理完，该线程就应该立即重置这个socket上的EPOLLONESHOT事件，以确保这个socket下次可读时，其EPOLLIN事件可被触发，进而让其它线程有机会处理这个socket。使用EPOLLONESHOT事件能进一步减少可读、可写和异常事件的被触发的次数。
**无论哪种情况下，epoll都比select和poll高效吗？**
epoll适用于连接较多，活动数量较少的情况。 
(1)epoll为了实现返回就绪的文件描述符，维护了一个红黑树和好多个等待队列，内核开销很大。如果此时监听了很少的文件描述符，底层的开销会得不偿失；
(2)epoll中注册了回调函数，当有事件发生时，服务器设备驱动调用回调函数将就绪的fd挂在rdllist上，如果有很多的活动，同一时间需要调用的回调函数数量太多，服务器压力太大。
select和poll适用于连接较少的情况。 
当select和poll上监听的fd数量较少，内核通知用户现在有就绪事件发生，应用程序判断当前是哪个fd就绪所消耗的时间复杂度就会大大减小。
## 线程池，内存池 自己动手实现一遍

## connect会阻塞，怎么解决?(必考必问，提示：设置非阻塞，返回之后用select检测状态)
1. 使用定时器
2. 使用非阻塞，将sockfd设置成非阻塞的，然后将sockfd加入select读写监听集合。返回之后用select检测状态
## 如果select返回可读，结果只读到0字节，什么情况？
某个套接字集合中没有准备好，可能会select内存用FD_CLR清该位为0


## socket什么情况下可读/可写？
1. socket接受缓冲区中已经接受的数据的字节数大于等于socket接受缓冲区低潮限度的当前值，对于这样的socket的读操作不会阻塞并返回大于0的值
2. 连接的读这一半关闭(即接收到对方发过来的FIN)，对于这样的socket的读操作将不阻塞，并且返回0
3. socket是一个监听的socket，并且已经完成的连接数为非0。
4. socket有异常错误待处理，对于这样的socket的读操作不会阻塞并且返回一个-1表示错误

以下情况下可写：
1. socket发送缓冲区的可用空间的字节数大于等于socket发送缓冲区低潮限度的当前值。对这些的socket。且socket不需要连接（UDP）或已经连接。这样的socket可以写并且返回一个正值。
2. 连接的写这一半关闭，对于这样的socket的写操作将会产生信号SIGPIPE。

# Linux的API
## fork与vfork区别 
  	fork和vfork都用于创建子进程。但是vfork创建子进程后，父进程阻塞，直到子进程调用exit()或者excle()。 
	fork、vfork、clone最后都调用do_fork()。do_fork()中调用copy_process()函数先复制task_struct结构体，然后复制其他关于内存，文件，寄存器等信息。
	fork采用写时拷贝技术，因此子进程和父进程的页表指向相同的页框。
	vfork不需要拷贝页表，因为父进程会一直阻塞，所以子进程直接使用父进程页表。
	clone是linux为创建线程设计的(虽然也可以设计进程)。该函数需要传入一个函数，在子进程创建后执行，clone不会复制父进程的栈空间，而是创建一个新的空间。

## exit()与_exit()区别 
  exit()清理后进入内核，_exit()直接陷入内核。
## 孤儿进程是怎么产生的？ 
  父进程先退出子进程还没退出，子进程将被托管给init进程，这里的子进程就是孤儿进程
##僵死进程是怎么产生的？ 
  子进程退出，而父进程没有调用wait或waitpid获取子进程的状态信息，那么子进程的进程描述符仍然保存在系统中，进程称之为僵死进程
##僵死进程的危害？
  大量的僵死进程会占用进程号，系统所能使用的进程号是有限的，将因为没有可用的进程号而导致不能产生新的进程
##如何避免僵死进程的产生？通过信号机制（退出时发个信号给父进程让父进程调用wait函数）
  fork两次 
  第一个调用fork产生一个子进程
  子进程调用fork函数在子进程中再产生个子进程，也就是孙进程
  子进程执行exit函数时使自己终止，孙进程就成了孤儿进程，利用init进程托管它就不会变成僵死进程
  调用waitpid函数去避免子进程变成僵死进程。
  孙进程需要先睡觉一段时间。要保证子进程先于孙进程退出
##Linux是如何避免内存碎片的
  伙伴算法，用于管理物理内存，避免内存碎片;
##高速缓存Slab层用于管理内核分配内存，避免碎片。
##共享内存的实现原理？
##系统调用与库函数(open, close, create, lseek, write, read)
##同步方法有哪些？
##互斥锁，自旋锁，信号量，读写锁，屏障
##互斥锁与自旋锁的区别：互斥锁得不到资源的时候阻塞，不占用cpu资源。自旋锁得不到资源的时候，不停的查询，而然占用cpu资源。
##死锁
